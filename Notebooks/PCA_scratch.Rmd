---
output: html_document
---

In this post, we will extend what we did in the previous PCA tutorial by doing it from scratch in R. We will be focusing on Singular Value Decomposition (SVD), which is a tool for matrix factorization. SVD states that any matrix $M \in A^{m \times n} $ can be decomposed into the following:

$$M = U \Sigma V^{T}$$

where $U$ is an $m \times m$ unitary matrix, $\Sigma$ is a diagonal $m \times n$ matrix with non-negative real numbers on the diagonal, and $V$ is an $n \times n$ unitary matrix. If $M$ is real, then $U$ and $V$ are orthogonal matrices, or uncorrelated. $U$ and $V$ are equal to the eigenvectors of $MM^{t}$ and $M^{t}M$, respectively. The entries in $\Sigma$ are singular values of $M$. The number of non-zero singular values is equal to the rank of $M$. If you recall, the rank of a matrix is defined as the maximum number of linearly independent columns in the matrix. As it relates to PCA, these are the nummber of Principal Components. 

Performing SVD on the covariance matrix of $M$ is essentially PCA. We will be using the Iris dataset.

```{r}
data(iris)
D <- data.matrix(iris[,c(1:4)]) #Here we are only taking the first four columns as the last one is categorical data.
```

The covariance is defined as follows:

$$cov_{x,y} = \frac{\Sigma(x_{i}-\overline{x})(y_{i}-\overline{y})}{N-1}$$

First, we will center our data by subtracting each value by the of their respective column.

```{r}
xcenter = colMeans(D) #Find the mean of the column
print(xcenter)

D_centered <- D - rep(xcenter, rep.int(nrow(D), ncol(D)))
head(D_centered)
```

We will multiply the transposed form of our matrix by our matrix followed dividing by $N-1$, where N is number of rows. We will compare this to the R function `cov()`

```{r}
covariance = t(D_centered) %*% (D_centered)
covariance = covariance / (dim(D_centered)[1] - 1)
covariance
cov(D_centered)

cat('\n Are the values the same:', all(round(cov(D_centered) - covariance, 3) == 0)) 
```

Next, we will solve for $MM^{t}$ and $M^{t}M$ to find $U$ and $V$.

```{r}
MTM <- t(covariance) %*% covariance
MTM.e <- eigen(MTM)
V <- MTM.e$vectors
V
```

```{r}
MMT <- covariance %*% t(covariance)
MMT.e <- eigen(MMT)
U <- MMT.e$vectors
U
```

Note that here we find that $U$ and $V$ are equivalent. This is a special case because we are using the covariance matrix. Now we find the singular values $\Sigma$, which are the square roots of the non-zero eigenvalues of $MM^{t}$ and $M^{t}M$.

```{r}
sigma <- sqrt(MMT.e$values)
sigma <- sigma * diag(length(sigma))
sigma
```

Now recall the equation for SVD.

$$M = U \Sigma V^{T}$$

Now that, we have the decommposed values, we can recompose them using matrix multiplcation to recover our covariance matrix of the Iris dataset.

```{r}
M <- U %*% sigma %*% t(V)
M
covariance

cat('\n Are the values the same:', all(round(M - covariance, 3) == 0)) 
```

PCA is an orthoganol projection. To generate, we project our `D_centered` matrix using the rotation matrix `V`.

```{r}
pc <- D_centered %*% V
head(pc)
```

```{r}
pca_prcomp <- prcomp(D_centered, center = F)
head(pca_prcomp$x)
cat('\n Comparing our calculations to the R function prcommp:\n\n')
cat('\n Do we get the same rotation matrix:',  all(round(pca_prcomp$rotation - V, 3) == 0)) 
cat('\n Are the principal components the same:', all(round(pca_prcomp$x - pc, 3) == 0)) 
```

It looks like something is wrong with our. Upon closer inspection, it appears the third column has the opposite sign, which is a multiple of $-1$. Recall that $Au = \lambda u$, where $A$ is a vector, $u$ is the eigenvector, and $lambda$ is the eigenvalue.

If $Au = \lambda u$, then $A(ku) = Akv = k \lambda u = \lambda (ku)$. Therefore, any multiple of $u$ is also an eigenvector of $A$.
```{r}
V
pca_prcomp$rotation
```

```{r}
V[,3]  <- -V[,3]
pc[,3]  <- -pc[,3]
cat('\n Comparing our calculations to the R function prcommp:\n\n')
cat('\n Do we get the same rotation matrix:',  all(round(pca_prcomp$rotation - V, 3) == 0)) 
cat('\n Are the principal components the same:', all(round(pca_prcomp$x - pc, 3) == 0)) 
```


Sources and additional information:

<a href="https://www.datacamp.com/community/tutorials/pca-analysis-r" class="uri">https://www.datacamp.com/community/tutorials/pca-analysis-r</a>

<a href="https://wilkelab.org/classes/SDS348/2016_spring/worksheets/class9.html" class="uri">https://wilkelab.org/classes/SDS348/2016_spring/worksheets/class9.html</a>

<a href="https://medium.com/@ravikalia/pca-in-matrix-based-frameworks-9719e29cf7e6" class="uri">https://medium.com/@ravikalia/pca-in-matrix-based-frameworks-9719e29cf7e6</a>

<a href="https://rpubs.com/aaronsc32/singular-value-decomposition-r" class="uri">https://rpubs.com/aaronsc32/singular-value-decomposition-r</a>

