---
title: "Pincipal Component Analysis"
output: md_document
---

In this post, I will be discussing different matrix factoriztion techniques: Principal Component Analysis (PCA), Independent Componant Analysis, and Non-negative Matrix Factorization (NMF). These techniques can take messy high-dimensional datasets and projects the data to a lower dimension with structure and order.  

PCA is a type of dimensional reduction method that can assist us by identifying which variables contribute to the variation within the data. It is similar to fitting a best fit line onto a 2D graph, but in this case there may be more than three-dimensions of data. It is formulated in the language of linear algebra and is an often used technique in data science and bioinformatics. 

```{r}
library(ggplot2)
library(cowplot) # required to arrange multiple plots in a grid
library(dplyr)
```


We will be using the often cited `iris` dataset. As you can see, there are more than five dimensions of data. 

```{r}
head(iris)
```

Let us try to observe some patterns with different combinations of variables. 

```{r}
p1 <- ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width, color=Species)) + geom_point()
p2 <- ggplot(iris, aes(x=Sepal.Length, y=Petal.Length, color=Species)) + geom_point()
p3 <- ggplot(iris, aes(x=Petal.Length, y=Petal.Width, color=Species)) + geom_point()
p4 <- ggplot(iris, aes(x=Sepal.Width, y=Petal.Width, color=Species)) + geom_point()
plot_grid(p1, p2, p3, p4, labels = "AUTO")
```

As you can see from the graphs, petal length, petal width, and perhaps sepal length contribute the most to the differences between the three species. 

Let's try using PCA as a better method for detecting such patterns. First, we will only include numerical data. We will pass our dataset (excluding the Species column) into the function `prcomp`. `center` and `scale` will be set to true to scale the data to 0 mean and unit variance.

```{r}
iris.pca <- prcomp(iris[,1:4], center = TRUE, scale. = TRUE)
summary(iris.pca)
```

The main results are that Principal Components 1 and 2 explains the majority of the variance within the dataset. These values are derived from the eigenvectors and eigenvalues from the covariance matrix. 

To better understand, you will need a basic understanding of eigenvectors and eigenvalues. To simply put, an eigenvector is a vector whose direction remains unchanged after a linear transformation. In that regard, an eigenvector provides direction or orientation of the data, like 90 or 45 degrees. The change after a linear transformation is described as the eigenvalue. In other words, the variance or spread of the data is explained by the eigenvalue. In addition, an *n*-th dimensional matrix will have the same *n* eigenvectors/eigenvalues. Therefore, each principal component is an eigenvector and PC1 has the highest eigenvalue (highest variance).

We can observe the results of the linear transformation with `iris.pca$x`.  

```{r}
head(iris.pca$x)
```

Let's add back in the species data.

```{r}
pca_data <- data.frame(iris.pca$x, Species=iris$Species)
head(pca_data)
```

Next, we will plot the first two principal components as these would explain the highest variation within the data.

```{r}
ggplot(pca_data, aes(x=PC1, y=PC2, color=Species)) + geom_point()
```

We can observe that setosa separates  further from versicolor and virginica. To understand which variables contribute to this variation in the data, we will call `iris.pca$rotation`.

```{r}
iris.pca$rotation
```

Here we can see that `Sepal.Length`, `Petal.Length`, and `Petal.Width` contributes quite a bit to PC1 compared to `Sepal.Width`. However, Sepal.Width contributes greatly to PC2. 

Therefore, based on the above graph, we can infer that variance in the x-axis is due to `Sepal.Length`, `Petal.Length`, and `Petal.Width` and variance in the y-axis is due to `Sepal.Width`. Running the following code will show this concept as vectors. 

```{r}
# capture the rotation matrix in a data frame
rotation_data <- data.frame(iris.pca$rotation, variable=row.names(iris.pca$rotation))
# define a pleasing arrow style
arrow_style <- arrow(length = unit(0.05, "inches"),
                     type = "closed")
# now plot, using geom_segment() for arrows and geom_text for labels
ggplot(rotation_data) + 
  geom_segment(aes(xend=PC1, yend=PC2), x=0, y=0, arrow=arrow_style) + 
  geom_text(aes(x=PC1, y=PC2, label=variable), hjust=0, size=3, color='blue') + 
  xlim(-1.,1.25) + 
  ylim(-1.,1.) +
  coord_fixed() # fix aspect ratio to 1:1
```

As you can see, before performing a PCA, we used four graphs to observe the conclusion that petal length, petal width, and sepal length contributed the most to the variance in species. With PCA, we could easily observe this with the PCA plot of PC1 vs PC2. In addition, we used a simple dataset to illustrate this. Many real-world datasets consists of much higher dimensions. 

Sources and additional information:

https://www.datacamp.com/community/tutorials/pca-analysis-r

https://wilkelab.org/classes/SDS348/2016_spring/worksheets/class9.html

```{r}
library(fastICA)
```

```{r}
S <- matrix(runif(10000), 5000, 2)
head(S,5)
```

```{r}
plot(S, main = "Source Data with Two Independent Components", xlab = "1st Dimension in S", ylab = "2nd Dimension in S")
```

```{r}
A <- matrix(c(1, 1, -1, 3), 2, 2, byrow = TRUE)
A
```

```{r}
X <- S %*% A
head(X,5)
```

```{r}
plot(X, main = "Linearly Mixed Data", xlab = "1st Dimension in X", ylab = "2nd Dimension in X")
```
```{r}
a <- fastICA(X, 2, alg.typ = "parallel", fun = "logcosh", alpha = 1,
method = "C", row.norm = FALSE, maxit = 200, # Symmetric FastICA using logcosh approx. to neg-entropy function
tol = 0.0001, verbose = TRUE)
```

```{r}
plot(a$X, main = "Pre-processed data", xlab = "1st Dimension in Centered X", ylab = "2nd Dimension in Centered X")
```
```{r}
plot(a$X %*% a$K, main = "PCA components", xlab = "1st PCA component", ylab = "2nd PCA component")
```
```{r}
a$W
```

```{r}
plot(a$S, main = "ICA components", xlab = "1st ICA component", ylab = "2nd ICA component")
```

```{r}
install.packages('NMF')
```

```{r}
library(NMF)
data(esGolub)
```


```{r}
esGolub <- esGolub[1:200,]
# remove the uneeded variable 'Sample' from the phenotypic data
esGolub$Sample <- NULL 
```

```{r}
res <- nmf(esGolub, 3)
```

```{r}
w <- basis(res)
dim(w)
# get matrix H
h <- coef(res) 
dim(h)
```


```{r}
s <- featureScore(res)
summary(s)

s <- extractFeatures(res) 
str(s)
```

```{r}
library(pixmap) 

```
```{r}
library(imager) 
library(ggplot2)
faces <- load.image ('images.png') 
faces <- grayscale(faces)
#faces <- as.cimg(faces[1:180, 1:256,1 ,1 ])
df <- as.data.frame(faces)
ggplot(df,aes(x,-y))+geom_raster(aes(fill=value)) + scale_fill_gradient(low="black",high="white")  + theme_void() + theme(legend.position = 'none')
```

```{r}
plot <- list()
for(i in 1:25)
{
df <- matrix(w[,i],25,27) %>% as.data.frame()
colnames(df) <- c(1:length(colnames(df)))
df <- pmin(df,1) 
df$x <- rownames(df)
df <- df %>% pivot_longer(as.character(1:25),names_to = "y")
plot[[i]] <- ggplot(df,aes(x,y))+geom_raster(aes(fill=value)) + scale_fill_gradient(low="black",high="white")  + theme_void() + theme(legend.position = 'none')
}
cowplot::plot_grid(plotlist = plot)
```

```{r}
basismap(aout)
```



```{r}
a <- faces[,,1,1]
aout <- nmf(a,25) 
w <- aout@fit@W
h <- aout@fit@H
```

```{r}
approxa <- w[,1:25] %*% h[1:25, ,drop = FALSE]
approxa <- pmin(approxa,1) 
facesnew <- faces
facesnew [,,1,1] <- approxa 
plot(facesnew) 
```


```{r}
plot <- list()
for (i in 1:16)
{
  approxa <- w[,i] %*% h[i, ,drop = FALSE]
  # brightness values must be in [0,1]
  approxa <- pmin(approxa,1) 
  facesnew <- faces
  facesnew[,,1,1] <- approxa 
  df <- grayscale(facesnew) %>% as.data.frame()
  plot[[i]] <- ggplot(df,aes(x,-y))+geom_raster(aes(fill=value)) + scale_fill_gradient(low="black",high="white")  + theme_void() + theme(legend.position = 'none')
}
cowplot::plot_grid(plotlist = plot)
```


```{r}
a <- faces[,,1,1]
pr.comp <- prcomp(a, center = TRUE, scale. = TRUE, rank = 25)
mu = colMeans(a)
plot <- list()

Xhat = pr.comp$x[,1] %*% t(pr.comp$rotation[,1])
Xhat = scale(Xhat, center = -mu, scale = FALSE)
approxa <- pmin(rescale(Xhat, c(0,1)),1) 
  facesnew <- faces
  facesnew[,,1,1] <- approxa 
plot(facesnew) 
```

```{r}
for (i in 1:16)
{
  Xhat = pr.comp$x[,i] %*% t(pr.comp$rotation[,i])
  Xhat = scale(Xhat, center = -mu, scale = FALSE)
  approxa <- pmin(rescale(Xhat, c(0,1)),1) 
  facesnew <- faces
  facesnew[,,1,1] <- approxa 
  df <- grayscale(facesnew) %>% as.data.frame()
  plot[[i]] <- ggplot(df,aes(x,-y))+geom_raster(aes(fill=value)) + scale_fill_gradient(low="black",high="white")  + theme_void() + theme(legend.position = 'none')
}
cowplot::plot_grid(plotlist = plot)
```






